{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6f36f2",
   "metadata": {},
   "source": [
    "# 10. 트랜스포머로 만드는 대화형 챗봇\n",
    "\n",
    "- 평가기준\n",
    "1. 한국어 전처리를 통해 학습 데이터셋 구축\n",
    ": 공백, 특수문자처리, 토크나이징, 병렬 데이터 구축\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습 정상적 진행\n",
    ": 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적 수렴\n",
    "3. 한국어 입력 문장에 대해 한국어로 대답하는 함수 구현\n",
    ": 한국어 입력 문장 맥락에 맞는 한국어로 답변 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c8a2f",
   "metadata": {},
   "source": [
    "#### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b43d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666f874",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기\n",
    "\n",
    "- cloud shell을 통한 다운로드를 진행함. \n",
    "- 데이터 출처 : https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad14e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일을 다운로드하고 압축 해제\n",
    "path_to_csv = tf.keras.utils.get_file(\n",
    "    'ChatbotData.csv', \n",
    "    origin='https://github.com/songys/Chatbot_data/raw/master/ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb8514",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d7a0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f65a63",
   "metadata": {},
   "source": [
    "### 한글 전처리를 위한 함수 수정\n",
    "- 영문 전처리에서 사용하던 소문자화 부분을 제외함. 공백 제거만 사용.\n",
    "- 구두점 사이 거리를 만드는 코드 그대로 사용\n",
    "- 구두점 제외 문자열 추출 과정에서 한국어 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22fd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 구두점과 단어 사이의 거리를 만듦\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # 구두점 제외 문자열 추출 (한국어, 영어, 숫자만 남김)\n",
    "    sentence = re.sub(\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 연속된 ㅋ, ㅎ, ㅠ 정규화 - 승환님 참고 \n",
    "    sentence = re.sub(r'ㅋ{2,}', 'ㅋㅋ', sentence)\n",
    "    sentence = re.sub(r'ㅎ{2,}', 'ㅎㅎ', sentence)\n",
    "    sentence = re.sub(r'ㅠ{2,}', 'ㅠㅠ', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "791912ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터를 로드하고 전처리하는 함수\n",
    "def load_conversations():\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    # CSV 파일 열기\n",
    "    with open(path_to_csv, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # 첫 번째 줄(헤더)을 건너뜀\n",
    "        \n",
    "        for row in reader:\n",
    "            # 각 행에서 질문과 답변을 추출\n",
    "            question, answer = row[0], row[1]\n",
    "            \n",
    "            # 전처리 함수를 질문과 답변에 적용\n",
    "            inputs.append(preprocess_sentence(question))\n",
    "            outputs.append(preprocess_sentence(answer))\n",
    "            \n",
    "            # 최대 샘플 수만큼 데이터를 가져옴\n",
    "            if len(inputs) >= MAX_SAMPLES:\n",
    "                break\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d2b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4c84c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b63b1",
   "metadata": {},
   "source": [
    "## Step3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d93c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70162b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d62f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8162]\n",
      "END_TOKEN의 번호 : [8163]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3453dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8164\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e082c6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5757, 610, 2486, 4158]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2355, 7502, 7, 6266, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca4b68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 15\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91b9627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b7af653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8164\n",
      "필터링 후의 질문 샘플 개수: 11571\n",
      "필터링 후의 답변 샘플 개수: 11571\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d64cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a786057",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adac37d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e7a8267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0227a61",
   "metadata": {},
   "source": [
    "- scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d1508d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a99875",
   "metadata": {},
   "source": [
    "- multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a1e3445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8afe7",
   "metadata": {},
   "source": [
    "- look ahead mask 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9c90716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f92e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a07598",
   "metadata": {},
   "source": [
    "- encoder 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac30525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f11e415e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45138e46",
   "metadata": {},
   "source": [
    "- decoder 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f0eec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "222eeea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e4701",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4348f0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    4198400     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5253120     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8164)   2098148     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,549,668\n",
      "Trainable params: 11,549,668\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.01 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c14e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=4,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model2 = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=8,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model3 = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=16,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee668ba6",
   "metadata": {},
   "source": [
    "### 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfa9c41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e96d9b5",
   "metadata": {},
   "source": [
    "### 커스텀된 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a7a1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.6)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e71109d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c44dd",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9c0389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model1.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de3004",
   "metadata": {},
   "source": [
    "### 훈련하기\n",
    "- 정확도가 낮게 나오는 이유가 model 복잡도가 낮기 때문이라고 생각했음\n",
    "\n",
    "→ encoder, decoder 층의 깊이를 제어하는 num layer를 4, 8, 16으로 늘려 3개의 모델을 테스트 해봄.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f18c4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 19s 71ms/step - loss: 4.2117 - accuracy: 0.0286\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 3.8859 - accuracy: 0.0955\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 3.6466 - accuracy: 0.1368\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 3.3895 - accuracy: 0.1375\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 3.1446 - accuracy: 0.1389\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 2.9150 - accuracy: 0.1392\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 2.7273 - accuracy: 0.1419\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 7s 72ms/step - loss: 2.5865 - accuracy: 0.1484\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 7s 72ms/step - loss: 2.4789 - accuracy: 0.1538\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 2.3852 - accuracy: 0.1582\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 2.2950 - accuracy: 0.1635\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 2.2064 - accuracy: 0.1695\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 2.1147 - accuracy: 0.1779\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 2.0189 - accuracy: 0.1879\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 1.9159 - accuracy: 0.1996\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 1.8056 - accuracy: 0.2138\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 1.6906 - accuracy: 0.2284\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 1.5725 - accuracy: 0.2440\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 1.4519 - accuracy: 0.2613\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 1.3312 - accuracy: 0.2781\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 1.2084 - accuracy: 0.2966\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 1.0861 - accuracy: 0.3162\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.9670 - accuracy: 0.3363\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.8496 - accuracy: 0.3551\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 7s 72ms/step - loss: 0.7357 - accuracy: 0.3743\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.6285 - accuracy: 0.3921\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.5257 - accuracy: 0.4089\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.4318 - accuracy: 0.4249\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.3475 - accuracy: 0.4381\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.2750 - accuracy: 0.4494\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.2146 - accuracy: 0.4576\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.1599 - accuracy: 0.4644\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.1197 - accuracy: 0.4679\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0916 - accuracy: 0.4699\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.0726 - accuracy: 0.4709\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.0581 - accuracy: 0.4714\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.0492 - accuracy: 0.4715\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0428 - accuracy: 0.4715\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0403 - accuracy: 0.4711\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0354 - accuracy: 0.4715\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0348 - accuracy: 0.4712\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0335 - accuracy: 0.4711\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0327 - accuracy: 0.4707\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0329 - accuracy: 0.4706\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0297 - accuracy: 0.4710\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.0305 - accuracy: 0.4706\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0312 - accuracy: 0.4704\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 6s 70ms/step - loss: 0.0302 - accuracy: 0.4705\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0283 - accuracy: 0.4705\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 6s 71ms/step - loss: 0.0316 - accuracy: 0.4698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x798ae66d6f10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model1.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "model1.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae0377e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 33s 123ms/step - loss: 2.8370 - accuracy: 0.0807\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8328 - accuracy: 0.0798\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8255 - accuracy: 0.0806\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8201 - accuracy: 0.0808\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8193 - accuracy: 0.0805\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8147 - accuracy: 0.0805\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 11s 122ms/step - loss: 2.8110 - accuracy: 0.0809\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8129 - accuracy: 0.0810\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8082 - accuracy: 0.0813\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 2.8096 - accuracy: 0.0810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x798b59ba6760>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model2.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "model2.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91260385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 67s 230ms/step - loss: 3.1551 - accuracy: 0.0702\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 21s 230ms/step - loss: 3.0087 - accuracy: 0.0713\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 21s 230ms/step - loss: 3.0028 - accuracy: 0.0714\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 21s 230ms/step - loss: 2.9997 - accuracy: 0.0711\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 21s 230ms/step - loss: 2.9948 - accuracy: 0.0720\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 21s 229ms/step - loss: 2.9739 - accuracy: 0.0743\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 21s 228ms/step - loss: 2.9410 - accuracy: 0.0754\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 21s 229ms/step - loss: 2.8919 - accuracy: 0.0777\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 21s 228ms/step - loss: 2.8664 - accuracy: 0.0789\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 21s 227ms/step - loss: 2.8548 - accuracy: 0.0795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x798a19101430>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model3.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "model3.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c58e6f",
   "metadata": {},
   "source": [
    "## Step5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e68975e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model3(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a55fe984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "    \n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "09d3820e",
   "metadata": {},
   "source": [
    "### 다른 모델에 대해 동일한 쿼리 실행\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cedb12d",
   "metadata": {},
   "source": [
    "- model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c991ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 하루가 또 가네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'하루가 또 가네요 .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b694c4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 1지망 학교가 떨어졌어\n",
      "출력 : 위로해 드립니다 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'위로해 드립니다 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('1지망 학교가 떨어졌어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2f21f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 3박 4일 놀러가고 싶다\n",
      "출력 : 배우자와 대화를 나눠보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'배우자와 대화를 나눠보세요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('3박 4일 놀러가고 싶다')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853852e1",
   "metadata": {},
   "source": [
    "- model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "095c1a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d2c32d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 1지망 학교가 떨어졌어\n",
      "출력 : 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('1지망 학교가 떨어졌어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75c3ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 3박 4일 놀러가고 싶다\n",
      "출력 : 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('3박 4일 놀러가고 싶다')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad742b",
   "metadata": {},
   "source": [
    "- model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "211be932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd75d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 1지망 학교가 떨어졌어\n",
      "출력 : 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('1지망 학교가 떨어졌어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02197904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 3박 4일 놀러가고 싶다\n",
      "출력 : 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 좋은 '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('3박 4일 놀러가고 싶다')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad5462",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "- 학습이 잘 일어나지 않았을때, 최대 길이만큼 텍스트를 반복한다는 것을 알게 됨. -> 최대 길이를 예상 대답 만큼 하는게 적합 한 것 같음.\n",
    "- 트랜스포머 모델의 깊이를 늘린다고 해서 항상 모델이 좋아지는건 아님.\n",
    "- 모델의 원리를 완벽히 파악하지 못해 하이퍼 파라미터 튜닝에 중점을 두고 진행함. 조금 더 보충 학습을 해서 모델에 대해 공부하고자 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571770ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
